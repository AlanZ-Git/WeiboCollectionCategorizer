# 微博收藏分类 WeiboCollectionCategorizer

## 简介
这个项目可以读取用户自己的所有收藏微博，下载建库后取消收藏，再接入LLM对收藏微博进行分类，方便取用

## 起因
我的微博收藏已经有6000条了，完全没法看，打算做一个爬虫脚本，把收藏的微博导出到本地数据库，再分类处理

## 声明
本项目主要靠Cursor - Claude Sonnet 3.7制作，我负责提需求及逻辑梳理，做测试和debug建议

## 参考
没写过微博爬虫，将 [Weibo Crawler](https://github.com/dataabc/weibo-crawler) 拉了下来作为Submodule方便参考，有些逻辑AI理不清的时候让他直接看大佬的解决方案

## 完成功能
通过csv批量输入微博链接下载
- 微博信息
- 微博正文及转发内容
- 图片
- livephoto
- 视频

读取个人收藏列表并保存csv

## 待办
读取
- 反复读取收藏列表还要考虑去重
- 微博发布时间/完成发布时间（编辑？）还是要引入字段保存，作为排序依据

下载
- 转发内容里如果带链接、图片、视频是否能顺利显示还没测试
- 微博文章是否下载还没想好
- 下载失败
    - 在大批量下载的时候，如果他下载media（pics, livephoto, videos）失败应该怎么标记
    - 需要一个根据下载media失败标记，补充下载的功能。
    - 整条微博都下载失败的话也需要标记以及补充下载功能
- 重复下载
    - 可以根据source_url判断
    - 有原博又有转发的，保留转发那条
    - 如果还有两条retweet_source_url都不一样的，两条同时保留

下载后微博操作
- 批量取消收藏微博不稳定，根据下载任务清单的任务完成情况来取消

数据储存
- csv保存是临时的，要引入数据库，轻量化点sqlite能解决，最近在学习mysql可以也写一套

微博分类
- 接入LLM api，之前一直用Cherry Studio就够，现在要引入编程工作流程了